{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "[https://pytorch.org/audio/stable/tutorials/audio_io_tutorial.html]\n",
    "\n",
    "[https://www.kaggle.com/code/enrcdamn/tempo-estimation-and-beat-tracking-pipeline]\n",
    "\n",
    "[https://lo.calho.st/posts/numpy-spectrogram/]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary packages with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_window_size = 256 # Should be a a value 2^x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load('superhero_64kbps.mp3')\n",
    "print(\"Sample Rate = \", sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = waveform.shape[1] / sample_rate\n",
    "print(\"audio length (seconds) = \", audio_length)\n",
    "print(\"audio length (mins and secs) = \", f\"{audio_length//60:.0f}\", \"m\", f\"{audio_length%60:.2f}\", \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(\"waveform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", start_time=0, end_time=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    print(\"Num Channels = \", num_channels)\n",
    "    print(\"Num Frames = \", num_frames)\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        num_samples_start = sample_rate*start_time\n",
    "        if end_time:\n",
    "            num_samples_end = sample_rate*end_time\n",
    "        else:\n",
    "            num_samples_end = len(waveform[c])\n",
    "        axes[c].specgram(waveform[c][num_samples_start:num_samples_end], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_specgram(waveform, sample_rate, start_time=15, end_time=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts:\n",
    "\n",
    "Idea 1: Compute the average frequency of the whole song.  Times frames at which the average frequency is significantly lower than average are considered 'drum beats'.\n",
    "\n",
    "Idea 2: Compute the average power of the whole song.  Time frames at higher power are 'drum beats'.\n",
    "\n",
    "Idea 3: Simple power threshold as a % of the max power.  (This is done below 17/07/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power(waveform, sample_rate, fft_window_size):\n",
    "    #waveform = waveform.numpy()\n",
    "\n",
    "    spectrogram_machine = T.Spectrogram(n_fft=fft_window_size)\n",
    "    spec = spectrogram_machine(waveform)\n",
    "    spec = spec.numpy()\n",
    "    print(\"(Channel, freq, time) = \", spec.shape)\n",
    "\n",
    "    power = []\n",
    "    for time_index in range(len(spec[0][0][:])):\n",
    "        sum = 0\n",
    "        for freq_index in range(len(spec[0][0:-1])):\n",
    "            sum += spec[0][freq_index][time_index]\n",
    "        power.append(sum)\n",
    "    \n",
    "    plt.plot(power)\n",
    "    print(max(power))\n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = compute_power(waveform, sample_rate, fft_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power(power, audio_length, start_time=None, end_time=None):\n",
    "    if start_time:\n",
    "        start_index = int((start_time/audio_length) * len(power))\n",
    "    else:\n",
    "        start_index = 0\n",
    "\n",
    "    if end_time:\n",
    "        end_index = int((end_time/audio_length) * len(power))\n",
    "    else:\n",
    "        end_index = len(power)\n",
    "    \n",
    "    print(start_index, end_index)\n",
    "\n",
    "    t = np.arange(start_index, end_index) * audio_length/len(power)\n",
    "    plt.plot(t, power[start_index:end_index])\n",
    "    \n",
    "    \n",
    "    plt.xlabel(\"Time (sec)\")\n",
    "    plt.ylabel(\"Integrated Power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power(power, audio_length, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple beat detector that just looks for power peaks within a certain % value of the maximum peak power.  It's not very good if the song has different phases/sections that differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_beats_from_power(power, audio_length, power_threshold_factor):\n",
    "    max_power = max(power)\n",
    "    power_threshold = power_threshold_factor*max_power\n",
    "    time_per_fft_frame = audio_length/len(power)\n",
    "    cooldown_time = 0.6\n",
    "    cooldown_frames = int(cooldown_time/time_per_fft_frame)\n",
    "    print(\"cooldown frames = \", cooldown_frames)\n",
    "\n",
    "    beat_times = []\n",
    "    cooldown_ticker = 0\n",
    "\n",
    "    for i in range(len(power)):\n",
    "        current_time = time_per_fft_frame * i\n",
    "        #print(\"current_time = \", current_time)\n",
    "\n",
    "        if cooldown_ticker > 0:\n",
    "            cooldown_ticker -= 1\n",
    "            continue\n",
    "\n",
    "        if power[i]>power_threshold:\n",
    "            beat_times.append(current_time)\n",
    "            cooldown_ticker = cooldown_frames\n",
    "\n",
    "    return beat_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_times = detect_beats_from_power(power, audio_length, 0.80)\n",
    "\n",
    "print(\"Number of beats detected = \", len(beat_times))\n",
    "print(beat_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try working with the frequencies in the spectrogram instead, maybe a better beat detector can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_freq(waveform, sample_rate, fft_window_size):\n",
    "    spectrogram_machine = T.Spectrogram(n_fft=fft_window_size)\n",
    "    spec = spectrogram_machine(waveform)\n",
    "    spec = spec.numpy()\n",
    "    print(\"(Channel, freq, time) = \", spec.shape)\n",
    "\n",
    "    avg_freq = []\n",
    "    for time_index in range(len(spec[0][0][0:-1])):\n",
    "        weighted_sum = 0.0\n",
    "        norm_factor = 0.0\n",
    "        for freq_index in range(len(spec[0][0:-1])):\n",
    "            current_freq = float(freq_index) * sample_rate/fft_window_size\n",
    "            weighted_sum += spec[0][freq_index][time_index]*current_freq\n",
    "            norm_factor += spec[0][freq_index][time_index]\n",
    "            #print(freq_index, \" \", weighted_sum, \" \", norm_factor)\n",
    "        avg_freq.append(weighted_sum / norm_factor)\n",
    "    \n",
    "    return avg_freq\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_freq(avg_freq, audio_length, start_time=None, end_time=None):\n",
    "    if start_time:\n",
    "        start_index = int((start_time/audio_length) * len(avg_freq))\n",
    "    else:\n",
    "        start_index = 0\n",
    "\n",
    "    if end_time:\n",
    "        end_index = int((end_time/audio_length) * len(avg_freq))\n",
    "    else:\n",
    "        end_index = len(avg_freq)\n",
    "    \n",
    "    print(start_index, end_index)\n",
    "\n",
    "    t = np.arange(start_index, end_index) * audio_length/len(avg_freq)\n",
    "    plt.plot(t, avg_freq[start_index:end_index])\n",
    "    \n",
    "    \n",
    "    plt.xlabel(\"Time (sec)\")\n",
    "    plt.ylabel(\"Average Frequency (Hz)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_freq = compute_avg_freq(waveform, sample_rate, fft_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_freq(avg_freq, audio_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_freq(avg_freq, audio_length, start_time=0, end_time=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
